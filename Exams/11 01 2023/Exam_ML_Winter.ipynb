{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qddQ-lKSdghB"
      },
      "source": [
        "# Билет 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZxzCfUXdghJ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "import typing as t\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7onIRt8FdghM"
      },
      "outputs": [],
      "source": [
        "# @formatter:off\n",
        "%matplotlib inline\n",
        "# @formatter:on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIQrKzukdghN",
        "outputId": "b5b9c1bf-2dda-4c2a-9abe-09f94eedad94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgGd8f0sdghP"
      },
      "outputs": [],
      "source": [
        "torch.set_warn_always(True)\n",
        "\n",
        "sns.set_theme()\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARCbucYrdghP",
        "outputId": "08008e53-6398-4779-bd3d-784692483e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU device\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"../data/\")\n",
        "\n",
        "CUDA = \"cuda\"\n",
        "CPU = \"cpu\"\n",
        "DEVICE = CUDA if torch.cuda.is_available() else CPU\n",
        "print(f\"Using {DEVICE.upper()} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyB-sDi4dghR"
      },
      "source": [
        "## Предобработка данных и подготовка датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fhNBvEcdghS"
      },
      "outputs": [],
      "source": [
        "def get_pos(word: str) -> str:\n",
        "    tag = nltk.pos_tag([word])[0][1]\n",
        "    if tag.startswith(\"J\"):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith(\"V\"):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith(\"R\"):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "\n",
        "_wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def wordnet_lemmatizer(token: str) -> str:\n",
        "    return _wordnet_lemmatizer.lemmatize(token, pos=get_pos(token))\n",
        "\n",
        "\n",
        "PATTERN = re.compile(r\"[^a-z]\", flags=re.MULTILINE)\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def preprocess_text(\n",
        "        text: str,\n",
        "        lemmatizer_or_stemmer: t.Callable[[str], str] = None,\n",
        "        min_word_len: int = 0,\n",
        ") -> str:\n",
        "    text = text.lower()\n",
        "    text = PATTERN.sub(\" \", text)\n",
        "\n",
        "    words = []\n",
        "    for word in nltk.word_tokenize(text):\n",
        "        if word not in STOPWORDS and len(word) >= min_word_len:\n",
        "            if not lemmatizer_or_stemmer:\n",
        "                words.append(word)\n",
        "                continue\n",
        "            word = lemmatizer_or_stemmer(word)\n",
        "            if word not in STOPWORDS and len(word) >= min_word_len:\n",
        "                words.append(word)\n",
        "\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzufC6D0dghT"
      },
      "outputs": [],
      "source": [
        "class ActivitiesVocab:\n",
        "    pad = \"<PAD>\"\n",
        "    unknown = \"<UNK>\"\n",
        "\n",
        "    def __init__(self, texts: t.List[str]):\n",
        "        uniques = set()\n",
        "        max_len = 0\n",
        "        for text in texts:\n",
        "            words = nltk.word_tokenize(text)\n",
        "            uniques.update(words)\n",
        "            max_len = max(len(words), max_len)\n",
        "\n",
        "        self.alphabet = [self.pad, self.unknown, *uniques]\n",
        "        self.max_len = max_len\n",
        "\n",
        "        w2i = {w: i for i, w in enumerate(self.alphabet)}\n",
        "        unknown_idx = w2i[self.unknown]\n",
        "        self.w2i = defaultdict(lambda: unknown_idx, w2i)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.alphabet)\n",
        "\n",
        "    def encode(self, text: str) -> torch.Tensor:\n",
        "        indices = [self.w2i[w] for w in nltk.word_tokenize(text)]\n",
        "        indices += [self.w2i[self.pad]] * (self.max_len - len(indices))\n",
        "        return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "    def decode(self, indices: torch.Tensor) -> str:\n",
        "        pad_indices = torch.nonzero(indices == self.w2i[self.pad], as_tuple=True)[0]  # noqa\n",
        "        if len(pad_indices):\n",
        "            indices = indices[:pad_indices[0]]\n",
        "        return \" \".join(self.alphabet[i] for i in indices)\n",
        "\n",
        "\n",
        "class ActivitiesDataset(Dataset):\n",
        "    df: pd.DataFrame\n",
        "    texts: t.List[str]\n",
        "\n",
        "    encoder: LabelEncoder\n",
        "    classes: t.List[str]\n",
        "\n",
        "    vocab: ActivitiesVocab\n",
        "    data: torch.Tensor\n",
        "    targets: torch.Tensor\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, vocab: ActivitiesVocab = None, encoder: LabelEncoder = None):\n",
        "        self.df = df\n",
        "\n",
        "        with tqdm(total=len(df)) as pbar:\n",
        "            self._pbar, self._i, self._n = pbar, 0, 100\n",
        "            self.texts = df[\"text\"].apply(self.preprocess_text).tolist()\n",
        "        self.vocab = vocab or ActivitiesVocab(self.texts)\n",
        "\n",
        "        if encoder:\n",
        "            self.encoder = encoder\n",
        "            encode = self.encoder.transform\n",
        "        else:\n",
        "            self.encoder = LabelEncoder()\n",
        "            encode = self.encoder.fit_transform\n",
        "\n",
        "        self.data = torch.vstack([self.vocab.encode(text) for text in self.texts])\n",
        "        targets = encode(df[\"type\"])\n",
        "        self.classes = self.encoder.classes_.tolist()\n",
        "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.targets[idx]\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        self._i += 1\n",
        "        if self._i % self._n == 0:\n",
        "            self._pbar.update(self._n)\n",
        "        return preprocess_text(text, lemmatizer_or_stemmer=wordnet_lemmatizer, min_word_len=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "wvVspgASdghU",
        "outputId": "4e505ce4-9da8-46c7-9449-9939b11c5aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "politics         345\n",
            "medical          299\n",
            "entertainment    260\n",
            "sports           258\n",
            "Name: type, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x180 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "activities_df = pd.read_csv(\"/content/tweet_cat.csv\")\n",
        "vc = activities_df[\"type\"].value_counts()\n",
        "print(vc)\n",
        "activities_df[\"type\"].value_counts().plot.bar(rot=0, figsize=(3, 2.5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjLZArGTdghV",
        "outputId": "8496d5e6-34ce-4530-b3fd-a1548068c46c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 900/929 [00:04<00:00, 209.74it/s]\n",
            " 86%|████████▌ | 200/233 [00:00<00:00, 444.00it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(929, 233)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_df, test_df = train_test_split(activities_df, test_size=0.2, random_state=0)\n",
        "\n",
        "train_dataset = ActivitiesDataset(train_df)\n",
        "test_dataset = ActivitiesDataset(test_df, vocab=train_dataset.vocab, encoder=train_dataset.encoder)\n",
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7jwUkt4dghV"
      },
      "source": [
        "## Построение и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSkT4W30dghW"
      },
      "outputs": [],
      "source": [
        "def get_weights(targets: torch.Tensor) -> torch.Tensor:\n",
        "    _, counts = targets.unique(return_counts=True)\n",
        "    return counts.max() / counts\n",
        "\n",
        "\n",
        "def common_train(\n",
        "        model: nn.Module,\n",
        "        loss_fn: nn.Module,\n",
        "        optimizer: optim.Optimizer,\n",
        "        epochs: int,\n",
        "        train_dataloader: DataLoader,\n",
        "        test_dataloader: DataLoader,\n",
        "        verbose: int = None,\n",
        "        device: str = CPU,\n",
        ") -> t.Tuple[t.List[float], t.List[float], t.List[float], t.List[float]]:\n",
        "    train_losses, train_accuracy_list = [], []\n",
        "    test_losses, test_accuracy_list = [], []\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}\\n\" + \"-\" * 32)\n",
        "\n",
        "        train_loss, train_accuracy = train_loop(train_dataloader, model, loss_fn, optimizer, verbose, device)\n",
        "        print(f\"Train Error: loss: {train_loss:.6f}, accuracy: {train_accuracy:.4f}\")\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "        test_loss, test_accuracy = test_loop(test_dataloader, model, loss_fn, device)\n",
        "        print(f\" Test Error: loss: {test_loss:.6f}, accuracy: {test_accuracy:.4f}\\n\")\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    return train_losses, train_accuracy_list, test_losses, test_accuracy_list\n",
        "\n",
        "\n",
        "def train_loop(\n",
        "        dataloader: DataLoader,\n",
        "        model: nn.Module,\n",
        "        loss_fn: nn.Module,\n",
        "        optimizer: optim.Optimizer,\n",
        "        verbose: int = None,\n",
        "        device: str = CPU,\n",
        ") -> t.Tuple[float, float]:\n",
        "    model.train()\n",
        "\n",
        "    size = len(dataloader.dataset)  # noqa\n",
        "    num_batches = len(dataloader)\n",
        "    avg_loss, avg_accuracy = 0, 0\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        y_true = torch.flatten(y).detach().cpu()\n",
        "        y_pred = torch.flatten(pred.argmax(1)).detach().cpu()\n",
        "        accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "        avg_loss += loss\n",
        "        avg_accuracy += accuracy\n",
        "        if verbose and batch % verbose == 0:\n",
        "            print(f\"[{batch * len(x):>4d}/{size:>4d}]: loss: {loss:.6f}, accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        del x, y, pred, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return (avg_loss / num_batches).item(), avg_accuracy / num_batches\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_loop(\n",
        "        dataloader: DataLoader,\n",
        "        model: nn.Module,\n",
        "        loss_fn: nn.Module,\n",
        "        device: str = CPU,\n",
        ") -> t.Tuple[float, float]:\n",
        "    model.eval()\n",
        "    y_true, y_pred = get_y_true_y_pred(model, dataloader, device)\n",
        "    return loss_fn(y_pred, y_true).item(), metrics.accuracy_score(y_true.cpu(), y_pred.argmax(1).cpu())\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_y_true_y_pred(\n",
        "        model: nn.Module,\n",
        "        dataloader: DataLoader,\n",
        "        device: str = CPU,\n",
        ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
        "    model.eval()\n",
        "\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x)\n",
        "        y_test.append(y)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "        del x\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return torch.flatten(torch.vstack(y_test)), torch.vstack(y_pred)\n",
        "\n",
        "\n",
        "def plot_train_test(\n",
        "        train_losses: t.List[float],\n",
        "        train_accuracy: t.List[float],\n",
        "        test_losses: t.List[float],\n",
        "        test_accuracy: t.List[float],\n",
        ") -> None:\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(6, 7))\n",
        "    epochs = torch.arange(len(train_losses))\n",
        "\n",
        "    axes[0].plot(epochs, train_losses)\n",
        "    axes[0].plot(epochs, test_losses)\n",
        "    axes[0].set_ylabel(\"loss\")\n",
        "    axes[0].legend([\"train\", \"test\"])\n",
        "\n",
        "    axes[1].plot(epochs, train_accuracy)\n",
        "    axes[1].plot(epochs, test_accuracy)\n",
        "    axes[1].set_xlabel(\"epoch\")\n",
        "    axes[1].set_ylabel(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka1zlk_rdghW"
      },
      "outputs": [],
      "source": [
        "class ActivitiesRNNClassifier(nn.Module):\n",
        "    _STATE_T = t.Union[t.Optional[torch.Tensor], t.Optional[t.Tuple[torch.Tensor, torch.Tensor]]]\n",
        "    rnn_state: _STATE_T\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_embeddings: int,\n",
        "            embedding_dim: int,\n",
        "            rnn_hidden_size: int,\n",
        "            vector_size: int,\n",
        "            num_classes: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=rnn_hidden_size, batch_first=True)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_hidden_size * vector_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(128, 5),\n",
        "            nn.Linear(5, num_classes),\n",
        "        )\n",
        "        self.reset_rnn_state()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        x, rnn_state = self.rnn(x, self.rnn_state)\n",
        "        self.keep_rnn_state(rnn_state)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "    def reset_rnn_state(self):\n",
        "        self.rnn_state = None\n",
        "\n",
        "    def keep_rnn_state(self, state: _STATE_T):\n",
        "        if isinstance(self.rnn, nn.LSTM):\n",
        "            self.rnn_state = (state[0].detach(), state[1].detach())\n",
        "        else:\n",
        "            self.rnn_state = state.detach()\n",
        "\n",
        "    def train(self, mode: bool = True):\n",
        "        self.reset_rnn_state()\n",
        "        return super().train(mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWGmDdJNdghX",
        "outputId": "dc8b5940-d665-4fae-f0e8-de9e4d8aa4b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ActivitiesRNNClassifier(\n",
              "  (embedding): Embedding(4996, 64, padding_idx=0)\n",
              "  (rnn): RNN(64, 64, batch_first=True)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1152, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=5, bias=True)\n",
              "    (4): Linear(in_features=5, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "net = ActivitiesRNNClassifier(\n",
        "    num_embeddings=len(train_dataset.vocab),\n",
        "    embedding_dim=64,\n",
        "    rnn_hidden_size=64,\n",
        "    vector_size=train_dataset.vocab.max_len,\n",
        "    num_classes=len(train_dataset.classes),\n",
        ").to(DEVICE)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=get_weights(train_dataset.targets).to(DEVICE))\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=33, shuffle=True, drop_last=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=512, drop_last=False)\n",
        "\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "Zzmzru7kdghY",
        "outputId": "f18b22a7-2bb6-4aa0-9e73-54fc04278fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "--------------------------------\n",
            "[   0/ 929]: loss: 1.364345, accuracy: 0.3939\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ded1f7812fc2>\u001b[0m in \u001b[0;36mcommon_train\u001b[0;34m(model, loss_fn, optimizer, epochs, train_dataloader, test_dataloader, verbose, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Error: loss: {train_loss:.6f}, accuracy: {train_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ded1f7812fc2>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, verbose, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-c93354aa7b12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_rnn_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RNN_TANH'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RNN_RELU'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    229\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 5, 64), got [1, 33, 64]"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train_losses, train_accuracy, test_losses, test_accuracy = common_train(\n",
        "    epochs=10,\n",
        "    model=net,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    train_dataloader=train_dataloader,\n",
        "    test_dataloader=test_dataloader,\n",
        "    verbose=50,\n",
        "    device=DEVICE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnSJYm_TdghY"
      },
      "outputs": [],
      "source": [
        "plot_train_test(train_losses, train_accuracy, test_losses, test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQSg1wYvdghZ"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = get_y_true_y_pred(net, test_dataloader, DEVICE)\n",
        "y_true, y_pred = y_true.cpu(), y_pred.argmax(1).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIzBseRmdghZ"
      },
      "outputs": [],
      "source": [
        "cm_display = metrics.ConfusionMatrixDisplay.from_predictions(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    display_labels=train_dataset.classes,\n",
        "    colorbar=False,\n",
        "    xticks_rotation=0,\n",
        "    cmap=sns.color_palette('light:b', as_cmap=True)\n",
        ")\n",
        "cm_display.ax_.grid(False)\n",
        "cm_display.figure_.set_size_inches(3.5, 3.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54EVb8Dsdgha"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(y_true, y_pred, target_names=train_dataset.classes, zero_division=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xbC5kiFdgha"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "for i in torch.randperm(len(test_dataset))[:5]:\n",
        "    x, y = test_dataset[i]\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    pred = net(x.unsqueeze(0))\n",
        "\n",
        "    pred_proba, pred_label_indices = torch.softmax(pred, 1).topk(min(len(test_dataset.classes), 3), dim=1)\n",
        "    pred_labels = test_dataset.encoder.inverse_transform(pred_label_indices.squeeze().cpu())\n",
        "    predicts = \", \".join([f\"{label} ({prob:.2f})\" for (label, prob) in zip(pred_labels, pred_proba.squeeze())])\n",
        "\n",
        "    text = test_dataset.texts[i]\n",
        "    text = text if len(text) < 80 else text[:80] + \"...\"\n",
        "    target = test_dataset.encoder.inverse_transform([y.cpu()])[0]\n",
        "\n",
        "    print(f\"Input:   {text}\")\n",
        "    print(f\"Target:  {target}\")\n",
        "    print(f\"Predict: {predicts}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 задача"
      ],
      "metadata": {
        "id": "9am2m1vuf3V3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggLQM1Vgdghb"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (3.5, 2.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "6oQr3Udjdghb",
        "outputId": "0dea7dfb-0069-44ba-eb2e-7956a6e20c9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def f(x: torch.Tensor) -> torch.Tensor:\n",
        "    return (x**2-25*x+10)/x\n",
        "\n",
        "\n",
        "SIGN = -1\n",
        "\n",
        "START, END = 0.5, 24\n",
        "EPS = 0.000001\n",
        "LR = 0.001\n",
        "\n",
        "X = torch.arange(START, END + 0.001, 0.001)\n",
        "Y = f(X)\n",
        "plt.plot(X.detach(), Y.detach());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v--HmlqYdghb"
      },
      "outputs": [],
      "source": [
        "SignT = t.Literal[-1, 1] \n",
        "FuncT = t.Callable[[torch.Tensor], torch.Tensor]\n",
        "\n",
        "\n",
        "def sign_func(func: FuncT, sign: SignT) -> FuncT:\n",
        "    return lambda x: -sign * func(x)\n",
        "\n",
        "\n",
        "def save_animation(xs: t.List[torch.Tensor], path: str, limit: int = 500, delay: int = 30) -> None:\n",
        "    xs_ = xs.copy()\n",
        "    delayed = xs_[-1]\n",
        "    if len(xs_) > limit:\n",
        "        xs_ = xs_[::len(xs_) // limit]\n",
        "    for i in range(delay):\n",
        "        xs_.append(delayed)\n",
        "\n",
        "    with tqdm(total=len(xs_) + 1) as pbar:\n",
        "        def animate(i):\n",
        "            scatter.set_data(xs_[i].detach(), f(xs_[i]).detach())\n",
        "            pbar.update()\n",
        "\n",
        "        fig, ax = plt.subplots(1, 1)\n",
        "        ax.plot(X.detach(), Y.detach())\n",
        "        scatter, = ax.plot([], [], marker=\"o\", color=\"r\")\n",
        "        anim = animation.FuncAnimation(fig, animate, interval=1, frames=len(xs_))\n",
        "        anim.save(path, writer=\"pillow\", fps=20)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def answer(x: torch.Tensor, sign: SignT, reason: str) -> None:\n",
        "    extrema = \"минимум\" if sign == -1 else \"максимум\"\n",
        "    if torch.isnan(x):\n",
        "        print(f\"Локальный {extrema} не найден\")\n",
        "    else:\n",
        "        x, y = x.item(), f(x).item()\n",
        "        print(f\"Найден локальный {extrema}: {x=:5f}, f(x)={y:5f}\")\n",
        "        plt.plot(X.detach(), Y.detach())\n",
        "        plt.scatter(x, y, color=\"r\")\n",
        "    print(f\"Причина остановки: {reason}\")\n",
        "\n",
        "\n",
        "def gradient_descent(\n",
        "        func: FuncT,\n",
        "        interval: t.Tuple[float, float],\n",
        "        sign: SignT,\n",
        "        eps: float,\n",
        "        lr: float,\n",
        "        initial_state: float = None,\n",
        ") -> t.Tuple[torch.Tensor, t.List[torch.Tensor], str]:\n",
        "    \"\"\"Градиентный спуск\"\"\"\n",
        "    sign_f = sign_func(func, sign)\n",
        "    start, end = interval\n",
        "    if initial_state is None:\n",
        "        initial_state = random.uniform(start, end)\n",
        "    elif initial_state < start or initial_state > end:\n",
        "        return torch.tensor(torch.nan), [torch.tensor(torch.nan)], \"initial_state вне интервала\"\n",
        "\n",
        "    interval_eps = lr * (end - start)  # наивное расширение границ интервала\n",
        "    adj_start, adj_end = start - interval_eps, end + interval_eps\n",
        "\n",
        "    x = torch.tensor(initial_state, dtype=torch.float, requires_grad=True)\n",
        "    if torch.isnan(sign_f(x)):\n",
        "        return torch.tensor(torch.nan), [torch.tensor(torch.nan)], f\"f(initial_state={initial_state:.4f}) не определена\"\n",
        "\n",
        "    i, n = 0, 1000\n",
        "    with tqdm() as pbar:\n",
        "        xs = []\n",
        "        while True:\n",
        "            xs.append(x.detach().clone())  # выполнится минимум 2 раза\n",
        "\n",
        "            if x < adj_start or x > adj_end:  # вышли за границу дальше дозволенного\n",
        "                # искомый экстремум - предыдущая позиция или одна из границ\n",
        "                start_t, end_t = torch.tensor(start), torch.tensor(end)\n",
        "                if start <= xs[-2] <= end:\n",
        "                    _, x = min((sign_f(xs[-2]), xs[-2]), (sign_f(start_t), start_t), (sign_f(end_t), end_t))\n",
        "                else:\n",
        "                    _, x = min((sign_f(start_t), start_t), (sign_f(end_t), end_t))\n",
        "                xs.append(x.detach().clone())\n",
        "                return xs[-1], xs, \"выход за границы интервала\"\n",
        "\n",
        "            y = sign_f(x)\n",
        "            if torch.isnan(y):\n",
        "                xs.pop()\n",
        "                return xs[-1], xs, f\"функция для следующего x={x.item():.4f} не определена\"\n",
        "\n",
        "            # а эти 3 строчки про \"возможности по автоматическому дифференцированию, которые предоставляет PyTorch\"\n",
        "            y.backward()\n",
        "            grad = x.grad.clone()\n",
        "            x.grad.zero_()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                x -= lr * grad  # ладно, это 4-ая\n",
        "                if torch.abs(x - xs[-1]) <= eps:  # найден экстремум с необходимой точностью\n",
        "                    xs.append(x.detach().clone())\n",
        "                    return xs[-1], xs, \"найден экстремум\"\n",
        "\n",
        "            if i % n == 0:\n",
        "                pbar.update(n)\n",
        "            i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "vU2NQdqidghc",
        "outputId": "dd5a6b9c-505a-4e80-c2b3-e5a3bd225153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18000it [00:03, 4867.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найден локальный минимум: x=3.163974, f(x)=-18.675446\n",
            "Причина остановки: найден экстремум\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAACrCAYAAABc6cGbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYXElEQVR4nO3deVhU190H8O/cWYBhX4dFEBXBAVTcgkkrJiYETECDRtGgbZrF1Cx9NWleydvnado0eVLbtzUxoaa8TTQprbugYjRGaqsGTRQNqyAi4DLDAMMyrMMs9/2DJaIo6Kz3zu/zl3LDPccTvpwz595zjoBlWRaEEE5jbF0BQojpKMiE8AAFmRAeoCATwgMUZEJ4gIJMCA9YJci1tbVIT09HUlIS0tPTUVdXZ41iCXEYVgny22+/jWeeeQZfffUVnnnmGfz617+2RrGEOAyBpV8IUavVSEpKwrfffguhUAiDwYD4+HgcPXoUPj4+Y7pHa2sXjMYfqunr6wa1utNSVeYdaq+xs9e2YhgBvL1d73hdZOkKKJVKyGQyCIVCAIBQKERAQACUSuWYg2w0ssOCPPg1MnbUXmPHxbayeJDNwdfX7bav+fu726Am3EXtNXZcbCuLBzkoKAgqlQoGg2FoaN3Y2IigoKAx30Ot7hz2W9Lf3x1NTR2WqC4vUXuNnb22FcMIRuzQhq5bugK+vr6Qy+XIz88HAOTn50Mul495WE0I37Esix6t3qR7WGXW+je/+Q1ycnKQlJSEnJwc/Pa3v7VGsYTYPZ3eiOyDFXg96xvo9Mb7vo9VPiNPmjQJu3fvtkZRhHBGd68OH+8rReXVNix7eBLEovvvVzkx2UUI37RoerFpdzEa1N14MTUaD8YEmnQ/CjIhVna9qRObdhWjR6vH+uXTER1u+nwRBZkQK7pY34qP95XCScwgM2MmwmTmedRFQSbESr6tUOHTQxUI8JZi/bLp8PV0Ntu9KciEWBjLsvjqu2vYdfwyIkO98NrSqXB1Fpu1DAoyIRZkNLLYUVCNY0XXMWdKAF5IkUMsEpq9HAoyIRai0xuQfbACRVVNeHxOKJYviAAjEFikLAoyIRbQ2aPDR3tLUH29HSsWRODxB8IsWh4FmRAza27vwaZdxWhq68HPF8fgAbnM4mVSkAkxo6uqDmzaVQyd3og30uMQFeZtlXIpyISYSXltC7JySyF1FuGXK2YixP/Oq5XMjYJMiBkUlimx9ctKBPlKsX55HLzdnaxaPgWZEBOwLIsvz9Rj73+uQD7eG6+kTYXU2fqxoiATcp+MRhb/+PoSjl+4gbnRMjz3pBwioW12mKYgE3IftDoDsg+U40J1MxbODcPS+ZMs9ox4LCjIhNwjTXcfNu8pQa1Cg4zESDw6a5ytq0RBJuReqFq7sWlXMVo7tHg5bSpmRfnbukoAKMiEjFnNjXZ8uKcEAPDmyhmICPG0cY1+QEEmZAwuXGrCXw+Uw9NNgvXL4xDoI7V1lYahIBMyioKi6/jnsUsID/TAfz09DR6uEltX6TYUZELuwMiy2PvvGhz+9iriIvzw0qIYOEnMvwTRHCjIhIxApzfi00MV+O5iIx6ZEYKMxEgwjO0eL42GgkzILbp6dfh4bymqrrXh6YcnYWF8GAQ2fEY8FhRkQm7S2NqN93POQ9XSjTWp0Zhr4ja11sL5INco2uHr4QwvN+u+pE7456qqA5v3lqBHa8Dr6XGQj7fOEkRzsGiQMzMzUVhYCG/v/gZJTk7G2rVrzVrGX3LLMDsqACsfm2zW+xLHUlarRlZuGdylEry1ajrGWXEJojlYvEdes2YNVq1aZdEyTD0Aizi2UyVKfH6kEkG+rnh37UMw9nHv54nzQ2uJiEGf3mDrahAOYlkWB76pw/5TtYgO71+C6OvpYpfHqo7G4muutm7ditTUVLz88suoqakx+/3FIsakU+yIY9IbjNh6uBL7T9XiodhArFs2HS5O3O3XTKp5WloaFArFiNcKCwuxfv16+Pv7g2EY5OXl4YUXXsCxY8cgFN7bQ/WRDngePFVe6iKGgGE4ecq8NVH7/KC7V4eNX5zD+apGpCdGIiNpyrDHS1xsKwHLsqy1CouPj8e+ffsQEhJyT9+nVnfCaPyhmjefKr/xH+fBAsjMmGnOqvLKze3l6No6tfhgdzGuN3bhJ8lRSJgePOy6vbYVwwhG7NCGrluycJVKNfTnkydPgmEYyGTm3RqUhtZkrBTNXXjviyKoWnrwi6en3RZiLrPoh4INGzZArVZDIBDAzc0NW7ZsgUhk3iL7g0yTXeTuqq624qO9pRCJGGzImIHwQA9bV8msLBrkbdu2WfL2AACJWIg+6pHJXXx3UYW/5VfAz9MFry+fDj8vF1tXyey4O003QCykoTUZ2c2nIE4e54nXlk6Dm4t5T0G0F9wPspiCTG5nNLLYXlCNgqLrmD0lAC9a6BREe8H5INMLIeRWfbr+UxDPX7L8KYj2gvNBHpy1ZlnW7peaEcvrGNjh8opCg5WPTUbi7FBbV8kqeBBkIVgWMBhZiIQUZEfWOLDDZUuHFi+nxWJWVICtq2Q13A/ywM7+fTqjzXb5J7ZXc6Mdm/eWwGhk8eaKGYgYZz87XFoD54MsEfeHV2egCS9HVVTVhOyD5fCy0x0urYHzQRaLBoKsowkvR3T07DXsLKjGxGAPvPb0NHhI7W+HS2vgTZDppRDHYjSy2FFQjWNF1zEr0h8vpkZDIubv46XRcD7IkoFng/Qs2XHcfIDa43NCsfyRCLve4dIaeBDkgaE1BdkhtHf1YfOeYtQ1dNjNAWr2gPNB/mFoTZ+R+U7R3IUPdhdD09WHV5dMxYzJ9nGAmj3gfJAHPxf16ahH5rOh1UtCATZkzMSEIH6tXjIV54PsPHCER6+OexumkbE5U96Az768CH8vF6xbNh3+PFy9ZCrOB9lpoEfW9tHQmm9YlsWh0/XYd+IKokK98OrSqXB15ufqJVNxPsiDPTIFmV/0BiNyjlbhRLESc2Nk+NlC+dB8CLkd54M8+Bm5l14I4Y0erR5b8spQVtuClIfCkTZvAi2IGQXngywSMhAJGeqReaK1o39zvBtNXXh24RRe7atlSZwPMtA/vKYemfuuNXbig93F6NHqsW75NMRO8LV1lTiDF0F2EgupR+a4slo1/pJbBhcnETIzZiJMxr29pW2JF0F2llCQuexksQKfH6lCsJ8r1i2bBh8PZ1tXiXN4EWQnGlpzEsuyyD15BfmF9Yid4IO1T8Vy+tgWW+JFq1GPzD06vRFbD1/EmXIVEqYHYdXjUbQxhAl4EWQnsRCarj5bV4OMUWePDln7SlF1rQ1LEibiyQfH0+MlE/EiyM4SIXqpR+YEVWs3PthdAnV7D9akRmNuTKCtq8QLJo9l9u/fj9TUVERHRyMnJ2fYtZ6eHqxbtw6JiYlITk7G8ePHTS1uRE4SEbT0GdnuXbrWhve+KEJXjw6/XDGDQmxGJvfIcrkcmzZtQnZ29m3XPv30U7i5ueHrr79GXV0dMjIycPToUbi6uppa7DDO9PjJ7g0ufPD1dMG6ZdMg83a8fbUsyeQeOTIyEhEREWCY2291+PBhpKenAwDCw8MRGxuLEydOmFrkbZwk/ec/3Xz0KrEPLMviwKlaZB+swKRgT/xq9SwKsQVY9DOyQqEYdhZyUFAQGhoazF7O4COLbq2et2f7cJFOb8S2w5U4Xd6Ah2ID8ezCKTQzbSGjBjktLQ0KhWLEa4WFhRAKLb/h2UgHPN98qrzMr/+6i6sT/H3NO2zni5vbyxo0XX3407bvUH5FjVXJU7D8sUjOzExbu63MYdQg5+bm3vfNg4ODcePGDfj4+AAAlEol4uPj7/k+anXnsGHzrafKGwc2FbimaIPQSDuF3OrW9rI0VWs3PthVDLWmF2sWRWNudCCamzutVr4prN1WY8UwghE7tKHrliw8OTkZO3fuBADU1dWhtLQU8+bNM3s5UueBoXUv7RJia0Mz0716vLlyBuZG08y0NZgc5Pz8fCQkJODIkSP48MMPkZCQgMuXLwMAnn/+eWg0GiQmJuKll17CO++8Aze3O/9WuV/SgV0jKMi2dbq8Af+74wJcXcT41U9mYfI4L1tXyWGYPNmVkpKClJSUEa9JpVJs3rzZ1CJGJb1psotYH8uyOPBNHfafqsWUMC+8nDaVJh2tjBdvdg0Orbt6dTauiePpn5m+iNPlKvwoNhA/pZlpm+BFkJ0lQjACAQ2trayzR4eP95bg0vV2pM2bgJSHwjkzM803vAiyQCCA1FlEQbYiVUs3PthdDLVGOzQzTWyHF0EG+ofX9BnZOi5da8NHe0sgEAjw5so4mtSyA/wJspOIPiNbwemyBmw9fBF+A+9MB9DrlnaBN0F2dRahh4bWFmNkWeSeuIJDp+tpZtoO8SfILmI0tffauhq8pO0z4G+HKlBU1US7edgp3gTZXSpBRzcNrc2ttUOLzXtKcFXVgRULIpA4J5Rmpu0Qb4LsIRWjR6uHTm+ko0XMpFapwea9JejtM+AXT0/D9Ag/W1eJ3AFvguzuKgEAdHT30XaqZnCushF/y6+Au1SCX62Kw7gA879aS8yHN0H2lA4GWUdBNgHLssgvrEPuyVpEhHji1SVT4THwS5LYL94EebBH1nTTbpr3S6c3YOuXlThTocKDMYF4dmEUxCLLrzcnpuNNkD2k/Y9CaFvc+9PeqcVH+0pxRaHB0vkT8cRc2qKWS3gTZPebhtbk3lxr7MSHe4rR2aPDK2mxmBUVYOsqkXvEmyA7S4QQixgaWt+jC9VNyD5QAamzCG9lzML4QO5tc0N4FGSBQAAPqZiG1mPEsiyOfHcVe47XIDzIHa8tnQYvNydbV4vcJ94EGQA83ZzQ1qm1dTXsnk5vxN+/qsKpUiXmTAnA80/KIRHTpBaX8SrIPu5OuN7UZetq2LW2Ti2y9pWiRqHBoh+FY/GPJ9CkFg/wK8gezii5ogbLsvTDOYJapQYf7ytFd68eLz8Vi9lTaFKLL3gX5D6dEV29tFH9rfqXH1bCy02C/1k9C6H0phav8CvI7v2TNS2aXgryAKORxWcHy5H778uYEuaFtU/FDj2qI/zBryAPvJrZotEiTEaPUbp7dfjkQDnKrrRgwcwQrHh0Mi0/5CmeBXmgR+6gdclKdRc27y1Fc1sPXnl6OmZF+Nq6SsSCeBVkD1cJhIwAao1jB7n4cjOyD5ZDJGTw5soZ+NHMULs8BoWYD6+CzAgE8PNyQVNrj62rYhMsy+LLM/XY958rCJW54bUl0+DrSSvBHAGvggwAgd4uaGhxvCD39umx7XAlvrvYiAfkAfjZE3I40UseDsPkmY/9+/cjNTUV0dHRyMnJGXYtMzMTCQkJWLx4MRYvXowtW7aYWtyoZD5SNLZ2w8g6zqHnqpZuvPdFEc5WNmLp/Il4aVEMhdjBmNwjy+VybNq0CdnZ2SNeX7NmDVatWmVqMWMW6CNFn96Itg6tQ2ww8H11M/4vvxyMQIDXl8chZoKPratEbMDkIEdGRgIAGMY+HmvIfPr3WW5o6eZ1kI0siwOnanHgmzqMl7njlbRY+Hm52LpaxEYs/hl569at2LlzJ0JDQ/HGG29g0qRJ93yPkQ54vtOp8oyk/5/U2Wfk5MnzY9HZ3Yc//fM8zl1U4dE5oVi7dPqoQ2m+toUlcLGtRg1yWloaFArFiNcKCwshFN75B2j9+vXw9/cHwzDIy8vDCy+8gGPHjt31e0aiVnfCaPzhM+/dTpVnWRYuTkJU1anxQCT/dn28qupAVm4pWjRarE6KwsNxwdC0dd/1e+7WXmQ4e20rhhGM2KENGjXIubm59124TCYb+vNTTz2F999/Hw0NDQgJCbnve45GIBAg1N8NV1X29z/DVKfLG/D54UpInUXYkDETESGetq4SsRMWHVqrVKqhMJ88eRIMwwwLt6WEydxxokQBo5EFw3B/FZROb8D2gsv494UbiAz1wtrFMfCkTQDITUwOcn5+Pv7whz9Ao9GgoKAA2dnZ+OyzzxAREYENGzZArVZDIBDAzc0NW7ZsgUhk+UfXYTJ39OmMULV2I8jX1eLlWZKqtRtb8spwVdWJ5PgwLEmYSO9Lk9uYnKqUlBSkpKSMeG3btm2m3v6+hMn6P0tcVXVyOsjnKhux9fBFMAIBfrF0GuIm8+8zPzEP3r3ZBQDBfq6QiBjUKNoRH235oby56fRG7Dp+GQVF1zEx2AM/XxwDP096tETujJdBFgkZTAz2wKVrbbauyj1rauvBJ/vLUKvsQOLsUCx7ZBINpcmoeBlkAIgK88aBU7Xo7tVB6syNTQaKqhqx9ctKsABeSZuKWVH+tq4S4QjeBjky1AssgOrr7XZ/iqC2z4DtBZdwoliJ8YHuWPtULALoLS1yD3gb5EnBHhAJGZTXtdh1kOsaNPjrgQo0tnRj4dwwpM2jWWly73j7EyMRCxET7o3vq5vB2uFKKCPL4vCZerz3RRH6dAb8cuUMLHs4gkJM7gtve2QAmBHpj+IaNa41dtrVHl4tml58eugiLta3YlakP366cAptFkhMwusgT4/wgwBAUVWTXQSZZVmcLFFi57+qYTCyeHbhFMybFkR7cBOT8TrInq4SRId745syJRb/eIJNX9ds0fRi25FKlF1pQVSoF372pJwmtIjZ8DrIAJAQF4IteWUoq23BtEnW30mSZVmcKlFix0AvnJEYiUdmhoChXpiYEe+DPGOyHzykYnx97prVg6xUdyHn6CVcrG/t74WfmIIAb6lV60AcA++DLBIySIoPw+7jNbh8o90qS//6dAYcOl2Pw9/WQywSYvXjkZg/g3phYjm8DzIALJgxDke+vYo9xy/jvzNmWixQLMvi+8vN2FFQjaa2XjwYI8PyBZPh6UpHtBDLcoggO0mEWDp/ErYdrsTJYgXmx5l/Y4NapQa7/nUZVdfaEOgjxZsr4iAPp43wiHU4RJABYN60IJwpb8D2gmpMDPY022mESnUXDn5ThzMVKrhLxVj1eCQSpgfTix3EqhwmyAKBAGsWxeCdbWfx4Z5ivLlyBmQmTDxdVXUg/3Q9iiobIRYzePLB8Xhi7ni4ODlMkxI7ImDt8f3FW9zL5nujqW/owJ92fg+GEeDF1GjE3DT81ZwpRPO+vdC3qCHy8YXfkqXwmPvQ0HWd3oBzVU34z4UbuHS9Hc4SIR6dNQ6Jc0LhYcdHldrrhnL2yF7barTN9xwuyACgaO7Cx/tK0dDSjTlTApA4JxR+V8vQ9PfPwfb1Df13AokE0hU/hSJgMi5UN6H4sho9Wj0CvFwwPy4YCXHBcOXAEkl7/eG0R/baVhTkO9DqDMgvrENB0XX09hkgNWrh19sCqUELAVh0CV3QJnaDRtzfeG4uYsRF+CE+WgZ5uDenHiXZ6w+nPbLXtjJ5O1y+chL3z2QvjB+P4ppmnPnHAaglnmgSuYCFAFKDFuN6mxDYfhFz1/0cE4LdIbST0zQIuZXDBnmQ1FmEB2MCIdNXQd+ovu26yMcXE8fR/tHEvlEXM8BvyVIIJMMnrAQSCfyWLLVRjQgZO4fvkQcNzk7fbdaaEHtFQb6Jx9yHKLiEkzgR5JHWEfPhKBhrovYaO3tsq9HqxInHT4SQu6PJLkJ4gIJMCA9QkAnhAQoyITxAQSaEByjIhPAABZkQHqAgE8IDFGRCeIBTQa6trUV6ejqSkpKQnp6Ouro6W1fJrmzcuBELFixAVFQULl26NPR1arfbtba24sUXX0RSUhJSU1Px6quvoqWlBQDw/fffY9GiRUhKSsJzzz0Htfr25a12h+WQ1atXs3l5eSzLsmxeXh67evVqG9fIvpw9e5ZVKBTsI488wlZVVQ19ndrtdq2treyZM2eG/v773/+efeutt1iDwcA+9thj7NmzZ1mWZdmsrCw2MzPTVtUcM870yGq1GhUVFUhJSQEApKSkoKKiYui3KAFmz56NoKCgYV+jdhuZl5cX4uPjh/4eFxcHhUKBsrIyODk5Yfbs2QCAFStW4MiRI7aq5phxJshKpRIymQxCoRAAIBQKERAQAKVSaeOa2Tdqt9EZjUZs374dCxYsgFKpRHBw8NA1Hx8fGI1GtLW12bCGo+NMkAmxlN/97neQSqVYtWqVraty3zixHhkAgoKCoFKpYDAYIBQKYTAY0NjYeNtQkgxH7XZ3GzduRH19PT755BMwDIOgoCAoFIqh6y0tLWAYBl5eXjas5eg40yP7+vpCLpcjPz8fAJCfnw+5XA4fHzpf6W6o3e7sz3/+M8rKypCVlQXJwH5tsbGx6O3txblz5wAAO3bsQHJysi2rOSac2ligpqYGmZmZ0Gg08PDwwMaNGzFx4kRbV8tuvPvuuzh69Ciam5vh7e0NLy8vHDp0iNptBNXV1UhJSUF4eDicnZ0BAOPGjUNWVhbOnz+Pt99+G1qtFiEhIfjjH/8IPz8/G9f47jgVZELIyDgztCaE3BkFmRAeoCATwgMUZEJ4gIJMCA9QkAnhAQoyITxAQSaEB/4fRlYMYvW+2o4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x, xs, reason = gradient_descent(func=f, interval=(START, END), sign=SIGN, eps=EPS, lr=LR, initial_state=9.1)\n",
        "answer(x, SIGN, reason)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dsHovqcdghc",
        "outputId": "79bc4fa9-7e36-4ba0-ca20-c58f542ce649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 540/540 [00:41<00:00, 13.12it/s]\n"
          ]
        }
      ],
      "source": [
        "save_animation(xs, \"autograd_1.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqLMnIfqdghc"
      },
      "source": [
        "![](autograd_1.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40u0Hp1Kdghc",
        "outputId": "d41cc5c2-67aa-4c34-b849-e0cf21a5e859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Локальный минимум не найден\n",
            "Причина остановки: initial_state вне интервала\n"
          ]
        }
      ],
      "source": [
        "x, xs, reason = gradient_descent(func=f, interval=(START, END), sign=SIGN, eps=EPS, lr=LR, initial_state=-6)\n",
        "answer(x, SIGN, reason)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJiOZfahdghc",
        "outputId": "e3f763af-6d53-43a2-866f-fdf8179c8409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:02<00:00, 10.88it/s]\n"
          ]
        }
      ],
      "source": [
        "save_animation(xs, \"autograd_2.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDNK0P0Sdghd"
      },
      "source": [
        "![](autograd_2.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCBKDET2dghd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gl8319Ldghd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}