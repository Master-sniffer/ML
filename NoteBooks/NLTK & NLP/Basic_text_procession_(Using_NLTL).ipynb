{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdB30U00gEAyTV2BWB4lWY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "metadata": {
        "id": "ZJZJcpr3fQUy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target_names #prints all the categories\n",
        "\n",
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])) #prints first line of the first data file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0SKMSwafRLe",
        "outputId": "ed90dbfc-4d3d-434c-f87a-0bf1992cc7b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFFI9YHwfSIX",
        "outputId": "5fb1510e-47f9-4db8-c19b-642e0de93915"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB9P0lhMfqVU",
        "outputId": "c7fb3ff5-e218-44f2-9842-1d3a32ead741"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "metadata": {
        "id": "MZU23-Zlf1Ej"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('clf', MultinomialNB()),\n",
        " ])\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "id": "TyhEGmjxf84i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0o24yAJgGf5",
        "outputId": "d90f9933-9bf0-4a7a-98ac-5e99a51adf71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                                            alpha=1e-3, max_iter=5, random_state=42)),\n",
        " ])\n",
        "_ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
        "np.mean(predicted_svm == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctr1Dgezgv5M",
        "outputId": "68e1ec12-f107-4190-fbae-967eda21f485"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8248805098247477"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "               'tfidf__use_idf': (True, False),\n",
        "               'clf__alpha': (1e-2, 1e-3),\n",
        " }"
      ],
      "metadata": {
        "id": "VDVCdRDqg133"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6MDQLwhixk",
        "outputId": "6993ae1f-697d-4082-d826-05943eaf4e93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gs_clf.best_score_)\n",
        "gs_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Moy5m_hmH8",
        "outputId": "57b65e4c-86a2-4a49-e15c-2c2d97e1c415"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "               'tfidf__use_idf': (True, False),\n",
        "               'clf-svm__alpha': (1e-2, 1e-3),\n",
        " }\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "gs_clf_svm.best_score_\n",
        "gs_clf_svm.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax52762thn-i",
        "outputId": "93273368-240e-4ad0-9538-3b3d11125e7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('clf', MultinomialNB()),\n",
        " ])"
      ],
      "metadata": {
        "id": "U7rNAEMKhylr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally using NLTK"
      ],
      "metadata": {
        "id": "RrQbjby8inh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
        "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
        "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('mnb', MultinomialNB(fit_prior=False)),\n",
        " ])\n",
        "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n",
        "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n",
        "np.mean(predicted_mnb_stemmed == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOkhIOEQie7u",
        "outputId": "aba4b86f-0acd-4a56-e6ad-029cd513a1dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8167817312798725"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MZvXQnpi9Be"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}